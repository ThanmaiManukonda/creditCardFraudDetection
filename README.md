# ğŸ’³ Credit Card Fraud Detection using Random Forest

## ğŸ“Œ Project Overview
This project focuses on detecting fraudulent credit card transactions using machine learning. Since fraud datasets are highly imbalanced, accuracy is not a reliable metric. Therefore, this project uses precision, recall, and F1-score for proper evaluation.

This task was completed as part of the **AI & ML Internship â€“ Task 9 (Ensemble Learning)**.

## ğŸ“‚ Dataset
- ğŸ“ Source: Kaggle Credit Card Fraud Dataset
- ğŸ’¼ Credit card transactions made by European cardholders
- ğŸ¯ Target column:
  - 0 â†’ Non-Fraud
  - 1 â†’ Fraud
- âš ï¸ Highly imbalanced dataset

## ğŸ›  Tools & Libraries Used
- ğŸ Python  
- ğŸ“Š Pandas  
- ğŸ”¢ NumPy  
- ğŸ¤– Scikit-learn  
- ğŸ“ˆ Matplotlib  
- ğŸ“‰ Seaborn  
- ğŸ’¾ Joblib  

## ğŸ§ª Models Implemented

### ğŸ”¹ Logistic Regression (Baseline Model)
- Used as a baseline for comparison
- ğŸ“ Feature scaling applied to fix convergence issues
- âš–ï¸ Class weighting used to handle class imbalance

### ğŸ”¹ Random Forest Classifier
- ğŸŒ² Ensemble learning technique
- Trained with 100 decision trees
- âœ… Performed better than Logistic Regression in fraud detection

## ğŸ“Š Evaluation Metrics
Due to class imbalance, the following metrics were used:
- ğŸ¯ Precision
- ğŸ” Recall
- ğŸ“Œ F1-score
- ğŸ§® Confusion Matrix

## ğŸ“ˆ Feature Importance
Feature importance was extracted from the Random Forest model to identify the most influential features contributing to fraud detection.

## ğŸ† Results
- Logistic Regression achieved high accuracy but lower fraud recall
- Random Forest improved recall and F1-score for fraud cases
- ğŸŒŸ Ensemble learning proved more effective for this problem

## ğŸ’¾ Model Saving
The trained model and scaler were saved using joblib:
- ğŸ“ credit_card_fraud_random_forest.pkl
- ğŸ“ scaler.pkl

## ğŸ“ Repository Structure
ğŸ“¦ Credit-Card-Fraud-Detection  
â”œâ”€â”€ ğŸ“„ creditcard.csv  
â”œâ”€â”€ ğŸ“˜ Credit_Card_Fraud_Detection.ipynb  
â”œâ”€â”€ ğŸ’¾ credit_card_fraud_random_forest.pkl  
â”œâ”€â”€ ğŸ’¾ scaler.pkl  
â”œâ”€â”€ ğŸ“ README.md  

## ğŸ Conclusion
Random Forest outperformed Logistic Regression in detecting fraudulent transactions. This project demonstrates the effectiveness of ensemble learning methods for handling imbalanced datasets.
